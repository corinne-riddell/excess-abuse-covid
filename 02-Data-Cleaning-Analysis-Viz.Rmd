---
title: "Excess Abuse Searches During COVID: Analysis and Data Visualization"
author: "Krista Neumann & Corinne Riddell"
date: "Original: 8/17/2021, Updated: 4/24/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Acknowlegment

The code used in this analysis was adapted from a Buzzfeed analysis of excess deaths due to the Texas Winter Storms. Their published R code is available here: https://github.com/BuzzFeedNews/2021-05-tx-winter-storm-deaths

# Setup

```{r, echo= FALSE}

# load required packages

library(tidyverse)
library(lubridate)
library(splines)
library(scales)
library(patchwork)
library(broom)
library(magrittr)
library(patchwork)
```

# Data import and cleaning

This code assumes an R project directory with the following sub-folders:

* WeeklyData - containing 3 csv files, one for each of the 3 abuse types. The csv files each contain multiple Google Search samples at the weekly resolution, as pulled via the "01-Pull-Data-From-API.py" file and formatted in wide format

* Plots - an empty folder where the data visualizations will be saved


Throughout this analysis we use the following acronyms: 

* "CM"  - Child abuse victimization ("child abuse")
* "DV"  - Child-witnessed intimate partner violence ("domestic violence")
* "IPV" - Intimate partner violence victimization ("intimate partner violence")

## Import Weekly Data

```{r}

# Load Weekly data. Single Data file includes all 10 samples for each abuse type. 

path <- "/Users/corinneriddell/Library/CloudStorage/Box-Box/Google-search-data/Excess Search NATIONAL Analysis/TEST/"


## investigate the distribution of the sampled measures to answer reviewer question
Weekly.CM0 <- read.csv(paste0(path, "WeeklyData/US-Weekly-CM.csv"),
                      stringsAsFactors = F)

Weekly.CM01 <- Weekly.CM0 %>% 
  pivot_longer(cols = c("sample_0":"sample_9"), 
               names_to = "SampleNo" , values_to = "value")

mean_med <- Weekly.CM01 %>% group_by(period) %>%
  summarise(mean = mean(value), 
         median = median(value),
         diff = mean - median,
         diff2 = diff/mean)

ggplot(mean_med, aes(x = diff2)) + geom_histogram(col = "white")
  

Weekly.CM <- Weekly.CM0 %>% 
  pivot_longer(cols = c("sample_0":"sample_9"), 
               names_to = "SampleNo" , values_to = "value") %>% 
  mutate(date = as.Date(period, format = "%Y-%m-%d")) %>% 
  group_by(date) %>% 
  summarise(mean_value = mean(value)) %>% 
  mutate(week_of_year = epiweek(date),
         abuse_type = "CM") 


Weekly.DV0 <- read.csv(paste0(path, "WeeklyData/US-Weekly-DV.csv"), 
                      stringsAsFactors = F)

Weekly.DV01 <- Weekly.DV0 %>% 
  pivot_longer(cols = c("sample_0":"sample_9"), 
               names_to = "SampleNo" , values_to = "value")

mean_med1 <- Weekly.DV01 %>% group_by(period) %>%
  summarise(mean = mean(value), 
         median = median(value),
         diff = mean - median,
         diff2 = diff/mean)

ggplot(mean_med1, aes(x = diff2)) + geom_histogram(col = "white")
  
Weekly.DV <- Weekly.DV0 %>% 
  pivot_longer(cols = c("sample_0":"sample_9"), names_to = "SampleNo" , values_to = "value") %>% 
  mutate(date = as.Date(period, format = "%Y-%m-%d")) %>% 
  group_by(date) %>% 
  summarise(mean_value = mean(value)) %>% 
  mutate(week_of_year = epiweek(date),
         abuse_type = "DV")  


Weekly.IPV0 <- read.csv(paste0(path, "WeeklyData/US-Weekly-IPV.csv"), 
                       stringsAsFactors = F)

Weekly.IPV01 <- Weekly.IPV0 %>% 
  pivot_longer(cols = c("sample_0":"sample_9"), 
               names_to = "SampleNo" , values_to = "value")

mean_med2 <- Weekly.IPV01 %>% group_by(period) %>%
  summarise(mean = mean(value), 
         median = median(value),
         diff = mean - median,
         diff2 = diff/mean)

ggplot(mean_med2, aes(x = diff2)) + geom_histogram(col = "white")

Weekly.IPV <- Weekly.IPV0 %>%
  pivot_longer(cols = c("sample_0":"sample_9"), names_to = "SampleNo" , values_to = "value") %>% 
  mutate(date = as.Date(period, format = "%Y-%m-%d")) %>% 
  group_by(date) %>% 
  summarise(mean_value = mean(value)) %>% 
  mutate(week_of_year = epiweek(date),
         abuse_type = "IPV") 

Weekly.Data <- rbind(Weekly.CM, Weekly.DV, Weekly.IPV)

# clean up environment
rm(Weekly.CM, Weekly.DV, Weekly.IPV )

```


```{r}
#descriptive stats and plots made to address reviewer comments

Weekly.Data %<>% mutate(year = year(date),
                        month = month(date))

Weekly.Data %>% group_by(abuse_type, year) %>%
  summarise(mean = mean(mean_value), 
            sd = sd(mean_value))
 
by_month <- Weekly.Data %>% group_by(abuse_type, month) %>%
  summarise(mean = mean(mean_value)) 

ggplot(by_month, aes(x = month, y = mean)) + geom_line(aes(col = abuse_type)) +
  theme_minimal() + labs(y = "Google search volume", x = "Month") + theme(legend.title=element_blank()) +
  scale_color_discrete(breaks=c("CM", "DV", "IPV"),
                         labels=c("Child abuse victimization", 
                                  "Child-witnessed IPV", 
                                  "IPV victimization")) +
  scale_x_continuous(breaks = c(1:12), 
                     labels = c("Jan", "Feb", "Mar", "Apr", "May", 
                                "Jun", "Jul", "Aug", "Sep", "Oct",
                                "Nov", "Dec"))

#for reviewer
#check for influential points/outliers
Weekly.Data %<>% mutate(abuse_type2 = case_when(abuse_type == "CM" ~ "Child abuse victimization", 
                                                abuse_type == "DV" ~ "Child-witnessed IPV", 
                                                abuse_type == "IPV" ~ "Intimate partner violence"))
ggplot(Weekly.Data, aes(x = mean_value)) + 
  geom_density() +
  facet_wrap(~abuse_type2, scales = "free_x") + 
  geom_rug() + 
  labs(x = "Google search volume") + 
  theme_bw()
```

# Main Analysis: Calculate expected search volume based on pre-pandemic data from 2017-2019

```{r}

# Data frame to hold observed and expected search volume
Weekly_Excess_Searches <- tibble()

adj_rsqs <- c(0, 0, 0)
counter <- 0

# Loop over each abuse type to create abuse-specific models and use them to predict expected search volume

for (i in unique(Weekly.Data$abuse_type)) {
  
  counter <- counter + 1
  Abuse.i.Weekly <- Weekly.Data %>% filter(abuse_type == i)
  
  # Restrict to pre-2020 data to build model
  Weekly.Data.pre2020 <- Abuse.i.Weekly %>% filter(date < "2020-01-01")

  
  # Fit model 
  Weekly.model <- lm(mean_value ~ date + 
                       ns(week_of_year, 
                          knots = quantile(week_of_year, c(0.1, 0.5, 0.9))), 
                     data = Weekly.Data.pre2020)

  # Store the adjusted r-squared value
  adj_rsqs[counter] <- broom::glance(Weekly.model) %>% pull(adj.r.squared)

  # Predicted expected search volume based on model for ENTIRE time period
  Weekly_pred <- as_tibble(predict(Weekly.model, Abuse.i.Weekly, 
                                   interval = "prediction"))
  
  # Add predictions to dataframe and then add to master Excess Search file
  Abuse.i.Weekly <- bind_cols(Abuse.i.Weekly, Weekly_pred)
  Weekly_Excess_Searches <- bind_rows(Weekly_Excess_Searches, Abuse.i.Weekly) 
  
  ### Check the linear model assumptions
  augmented_dat1 <- augment(Weekly.model)
  augmented_dat1 %<>% mutate(resid = mean_value - .fitted)

  # QQ plot - check Normality of the residuals
  plot2 <- ggplot(augmented_dat1, aes(sample = resid)) + 
    geom_qq() + 
    geom_qq_line() +
    theme_minimal(base_size = 15) +
    labs(y = "Residuals", x = "Theoretical quantiles", title = "(b) QQplot") 
  
  # Fitted vs. residuals
  plot3 <-ggplot(augmented_dat1, aes(y = resid, x = .fitted)) + 
    geom_point() + 
    theme_minimal(base_size = 15) +
    geom_hline(aes(yintercept = 0)) +
    labs(y = "Residuals", x = "Fitted values", title = "(c) Fitted vs. residuals") 
  
  # Save model assumptions plots
  Assumptions <- plot2 + plot3 + plot_layout(nrow = 2)
  ggsave(paste0("Plots/Model_Assumptions_",i,".png"), Assumptions, height = 7, width = 12, units = "in")
 
}

# Add an indicator for whether the year is 2020
Weekly_Excess_Searches <- Weekly_Excess_Searches %>% 
  mutate(after_2020 = as.factor(case_when(date >= as.Date("2020-01-01") ~ 1, 
                               date < as.Date("2020-01-01") ~ 0)))

# clean up environment
rm(Abuse.i.Weekly, Weekly.Data.pre2020, Weekly.model, Weekly_pred) 

```

# Data Visualizations

We save both the individual plots for each abuse type as well as the single combined figure. 

```{r}

# Set date labels for plots
date.vec = seq(from = as.Date("2017-01-01"),
               to = as.Date("2021-01-01"),
               by = "2 months")


# Child abuse victimization ----------------------------------------------------------------------------------------------

CM.Weekly.plot <- ggplot(Weekly_Excess_Searches %>% filter(abuse_type == "CM"), 
                         aes(y = mean_value, x = date)) +
  geom_ribbon(data = Weekly_Excess_Searches %>% filter(abuse_type == "CM"), 
              aes(ymin = lwr, ymax = upr, fill = after_2020), alpha = 0.1) +
  scale_fill_manual(values=c("black", "#189AB4")) +
  geom_vline(xintercept = as.Date("2020-03-19"), linetype = "dashed", color = "#FB475E", size = .8) +
  geom_vline(xintercept = as.Date("2020-04-11"), linetype = "dotdash", color = "#729663", size = .8) +
  geom_vline(xintercept = as.Date("2020-07-31"), linetype = "twodash", color = "#00B4D4", size = .8) +
  geom_point(aes(alpha = after_2020)) +
  scale_alpha_manual(values=c(0.5, 1)) +
  geom_line(aes(y = fit, x = date, alpha = after_2020), size = 1.05, color = '#175873') +
  theme_minimal(base_size = 16) +
  xlab("") + ylab("Search Outcome") +
  labs(title = "(A) Child abuse victimization") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = .7, vjust = .7),
        axis.title.y = element_text(vjust=2),
        panel.grid.minor = element_line(size = 0.3), 
        panel.grid.major = element_line(size = 1)) +
  scale_x_date(breaks = date.vec, date_labels = "%b-%y")

CM.Weekly.plot
ggsave("Plots/Weekly_Trends_CM.png", CM.Weekly.plot, height = 7, width = 12, units = "in")



# Child-witnessed IPV ----------------------------------------------------------------------------------------------

DV.Weekly.plot <- ggplot(Weekly_Excess_Searches %>% filter(abuse_type == "DV"), 
                         aes(y = mean_value, x = date)) +
  geom_ribbon(data = Weekly_Excess_Searches %>% filter(abuse_type == "DV"),
                           aes(ymin = lwr, ymax = upr, fill = after_2020), alpha = 0.1) +
  scale_fill_manual(values=c("black", "#189AB4")) +
  geom_vline(xintercept = as.Date("2020-03-19"), linetype = "dashed", color = "#FB475E", size = .8) +
  geom_vline(xintercept = as.Date("2020-04-11"), linetype = "dotdash", color = "#729663", size = .8) +
  geom_vline(xintercept = as.Date("2020-07-31"), linetype = "twodash", color = "#00B4D4", size = .8) +
  geom_point(aes(alpha = after_2020)) +
  scale_alpha_manual(values=c(0.5, 1)) +
  geom_line(aes(y = fit, x = date, alpha = after_2020), size = 1.05, color = '#175873') +
  theme_minimal(base_size = 16) +
  xlab("") + ylab("Search Outcome") +
  labs(title = "(B) Child-witnessed intimate partner violence") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = .7, vjust = .7),
        axis.title.y = element_text(vjust=2),
        panel.grid.minor = element_line(size = 0.3), 
        panel.grid.major = element_line(size = 1)) +
  scale_x_date(breaks = date.vec, date_labels = "%b-%y")

DV.Weekly.plot
ggsave("Plots/Weekly_Trends_DV.png", DV.Weekly.plot, height = 7, width = 12, units = "in")



# Intimate partner violence victimization  ------------------------------------------------------------------------

IPV.Weekly.plot <- ggplot(Weekly_Excess_Searches %>% filter(abuse_type == "IPV"), 
                          aes(y = mean_value, x = date)) +
  geom_ribbon(data = Weekly_Excess_Searches %>% filter(abuse_type == "IPV"),
              aes(ymin = lwr, ymax = upr, fill = after_2020), alpha = 0.1) +
  scale_fill_manual(values=c("black", "#189AB4")) +
  geom_vline(xintercept = as.Date("2020-03-19"), linetype = "dashed", color = "#FB475E", size = .8) +
  geom_vline(xintercept = as.Date("2020-04-11"), linetype = "dotdash", color = "#729663", size = .8) +
  geom_vline(xintercept = as.Date("2020-07-31"), linetype = "twodash", color = "#00B4D4", size = .8) +
  geom_point(aes(alpha = after_2020)) +
  scale_alpha_manual(values=c(0.5, 1)) +
  geom_line(aes(y = fit, x = date, alpha = after_2020), size = 1.05, color = '#175873') +
  theme_minimal(base_size = 16) +
  xlab("") + ylab("Search Outcome") +
  labs(title = "(C) Intimate partner violence victimization") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = .7, vjust = .7), #vjust = .5
        axis.title.y = element_text(vjust=2),
        panel.grid.minor = element_line(size = 0.3), 
        panel.grid.major = element_line(size = 1)) +
  scale_x_date(breaks = date.vec, date_labels = "%b-%y") 

IPV.Weekly.plot
ggsave("Plots/Weekly_Trends_IPV.png", IPV.Weekly.plot, height = 7, width = 12, units = "in")



# Combined Plot ----------------------------------------------------------------------------------------------

Weekly.Combined.plot <- CM.Weekly.plot/DV.Weekly.plot/IPV.Weekly.plot
ggsave("Plots/Weekly_Trends_Combined.png", Weekly.Combined.plot, height = 18, width = 16, units = "in", dpi = 150)

# Note: To add policy annotations to this plot, please refer to the 03-Excess-Search-Fig-Annotations InDesign file. Unless significant modifications were made to the size of the exported R images, you should just need to re-link the Weekly_Trends_Combined.png file to obtain an updated plot with annotations.

```
